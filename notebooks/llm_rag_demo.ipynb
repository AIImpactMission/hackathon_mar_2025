{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM with RAG demo\n",
    "**Note:** This is just some code to help you getting started, but in no way mandatory to use. Feel free to use any other tools, libraries, approaches, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:01:29.826103Z",
     "start_time": "2025-03-19T20:01:22.829729Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import pickle\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings.base import OpenAIEmbeddings\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.llm import get_llm_client, get_openai_embeddings_client\n",
    "\n",
    "if not load_dotenv():\n",
    "    raise Exception('Error loading .env file. Make sure to place a valid OPEN_AI_KEY in the .env file.')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:01:29.836126Z",
     "start_time": "2025-03-19T20:01:29.831099Z"
    }
   },
   "source": [
    "METADATA_PATH = os.path.join(\"..\", \"data\", \"metadata.csv\")\n",
    "ARTICLES_CLEAN_DIR = os.path.join(\"..\", \"data\", \"articles_clean\")\n",
    "DB_PATH = os.path.join(\"..\", \"data\", \"db\", \"sample.db\")\n",
    "if not os.path.exists(DB_PATH):\n",
    "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the metadata df according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "metadata[\"published_at\"] = pd.to_datetime(metadata[\"published_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata = metadata[\n",
    "    # Date\n",
    "    (metadata[\"published_at\"] >= \"2023-01-01\") &\n",
    "    # Word count\n",
    "    (metadata[\"words_count\"] >= 100) &\n",
    "    # Category\n",
    "    (metadata[\"category\"].str.contains(\"Wirtschaft\", case=False))\n",
    "]\n",
    "print(f\"Expected number of articles: {filtered_metadata.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Or load filtered articles"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:01:33.528051Z",
     "start_time": "2025-03-19T20:01:33.523876Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_metadata = pd.DataFrame({\"filename\": [\"1-coffee-to-berlin.json\", \"1-mai-schwere-ausschreitungen-in-hamburg.json\"]})",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:01:41.174176Z",
     "start_time": "2025-03-19T20:01:41.170370Z"
    }
   },
   "source": [
    "def load_articles(filtered_metadata, articles_dir):\n",
    "    \"\"\"\n",
    "    Load articles based on filtered metadata\n",
    "    \"\"\"\n",
    "    articles = []\n",
    "    for _, row in filtered_metadata.iterrows():\n",
    "        article_path = os.path.join(articles_dir, row[\"filename\"])\n",
    "        with open(article_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            article = json.load(file)\n",
    "            articles.append(article)\n",
    "    return articles"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:02:10.750966Z",
     "start_time": "2025-03-19T20:02:10.745114Z"
    }
   },
   "source": [
    "filtered_articles = load_articles(filtered_metadata, ARTICLES_CLEAN_DIR)\n",
    "print(f\"Sample article:\\n {filtered_articles[0]}\\n\")\n",
    "print(f\"Sample article metadata:\\n {filtered_metadata.iloc[0]}\\n\")\n",
    "print(f\"Number of selected articles: {len(filtered_articles)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample article:\n",
      " {'id': 'd52577f3-5d24-4138-b618-285588b9a670', 'published_at': '2012-11-02 18:00', 'author': 'Christine Zeiner', 'title': '\"1 Coffee to Berlin\"', 'category': 'Wirtschaft', 'ressort': 'Nachrichten', 'text': 'Die Übergabe in Edinburgh hat nicht geklappt. Das zweite Päckchen Kaffee holt nun ein schottischer Freund aus der Collective-Gallery in der Cockburnstreet ab. \"Failed\" vermerkt Kate im Shipmentreport. \"Nett, dass wir die Packung geteilt haben, so ist wenigstens ist ein Teil angekommen\", mailt sie mir.\\nKate Rich lebt in England und verkauft seit einigen Jahren Kaffee und andere Lebensmittel über soziale Netzwerke: direkt, informell und abseits der üblichen kommerziellen Kanäle. \"Feraltrade\" nennt die 43-jährige Künstlerin ihre Art, Geschäfte zu machen, \"Wilder Handel\" - ein \"öffentliches Experiment\", wie Kate sagt. Sich selbst bezeichnet sie als \"Infrastructure Artist\", als eine Künstlerin, die sich mit Netzwerken und Systemen auseinandersetzt.\\nKaffee aus El Salvador, Süßigkeiten aus dem Iran und Olivenöl aus Griechenland kommen im Koffer von reisenden Künstlern, Freunden und Freunden von Freunden an den jeweiligen Bestimmungsort mit. Zurzeit hat Kate Rich Kaffee, Olivenöl, die Open-Source-Rezept-Limo \"Cube Cola\" aus Großbritannien sowie Fisch aus Montenegro auf Lager. \"Total begehrt\" seien die auf der Webseite ebenfalls erwähnten iranischen Süßigkeiten - Kate konnte allerdings zuletzt keine Lieferung auf die Beine stellen. Auch kroatischer Grappa ist zurzeit nicht zu bekommen: Die bisherige Produzentin - Mutter einer Bekannten von Kate - fand noch keine Zeit, für Nachschub zu sorgen. Was gerade bei Kate bestellt werden kann, hängt also auch davon ab, ob die Produzenten ihre Waren aktuell anbieten und ob die Produkte über das Feraltrade-System geliefert werden können. Neue Vorschläge kann jeder machen. Kate erweitert ihr Sortiment dann einfach. Einzige Bedingung: Kate will mit Waren handeln, die man nirgendwo sonst bekommt. \"Bei Feraltrade muss man in Kontakt mit anderen Menschen treten, um an das Produkt zu kommen, mit dem Kurier kommunizieren und ihn treffen\", sagt sie. Feraltrade bedeutet also auch Abenteuer und Risiko und in gewisser Weise einen Schritt zurück in die Einkaufswelt von Früher, als man die Ladenbesitzer noch kannte und nicht ständig alle Produkte verfügbar waren. Auf der Feraltrade-Webseite ist die gesamte Lieferkette mit Fotos und Einträgen dokumentiert: Wo sich die Ware gerade befindet, kann genau nachvollzogen werden. Wer etwas bestellen möchte oder ein Produkt anzubieten hat, muss Kate eine Mail schicken. Einen Online-Shop gibt es nicht - \"zu anonym\". Der \"soziale Aspekt\" sei schließlich die Hauptmotivation bei Feraltrade. Wenn alles klappt, lernt man Menschen kennen, die man sonst nicht getroffen hätte. Wenn sie gefragt wird, ob man via Feraltrade auch andere Produkte, die es etwa in britischen Supermärkten zu kaufen gibt, beziehen kann, antwortet Kate: \"Das wäre nicht Feraltrade. Bau dir dafür doch auch ein soziales Netzwerk auf!\"\\nIch frage nach einer Packung Kaffee aus El Salavador an. \"Klar. Wenn du jemanden kennst, der in der nächsten Zeit von London nach Berlin reist, gib mir Bescheid\", antwortet Kate. Ich kenne niemanden. Ein paar Wochen später stehen die Urlaubsziele für das Jahr fest, geplant sind unter anderem ein paar Tage in Edinburgh. Ich schreibe Kate: \"Würde Edingburgh helfen?\" Eine Stunde später antwortet sie, das sei perfekt, sie habe soeben einen Kurier von Bristol nach Edinburgh gefunden. Kate hatte eine Rundmail geschickt: Wer in den nächsten Wochen nach Edinburgh reise, solle doch bitte so nett sein und ein Päckchen Kaffee dorthin mitnehmen. In Klammern setzt sie \"Endstation Berlin\". Daraufhin meldete sich Lea bei Kate. Ihre Freundin Iana aus Berlin käme zu Besuch, sie könnte den Kaffee gleich nach Deutschland mitnehmen. Kate fragt bei mir nach: \"Was ist dir am liebsten?\" Ich entscheide mich dafür, den Kaffee auf zwei Wegen zu erhalten.\\nÜber Kate und Lea bekomme ich die E-Mail-Adresse der Filmemacherin Iana Stevanova. Sie habe nur ein paar Stunden Zeit zwischen ihrer Ankunft aus Bristol in Berlin und ihrer Weiterreise nach Wien, wo sie an einem Projekt mitarbeitet, schreibt sie. Wir verbreden uns um 13.30 Uhr am Paul-Lincke-Ufer, Ecke Mariannenstraße; wir tratschen ein wenig, ich bekomme meinen Kaffee, mache ein Foto von der Übergabe und fahre zurück ins Büro. Dort überspiele ich das Bild und stelle es auf die Feraltrade-Webseite.\\nEs ist das Ende der Geschichte \"1 Coffee San Ramon to Berlin\". Den Anfang machten die US-Amerikaner Helen Cold und ihren Mann Matt Ferderbar, wie die Einträge und Fotos zeigen. Die zwei lernten die Kaffeebauern Adiloio Ceron Escobar und Blanca de Ceron in San Ramon, El Salvador, kennen. Cold und Ferderbar vermittelten den Kaffee an Kate. Auf die Feraltrade-Webseite stellten sie ein Foto der Kaffeebauern: Man sieht sie in ihrem Haus, die Großmutter schaukelt auf einer durch den einfachen Raum gespannten Hängematte. \"Hier im Haus schält die Familie die Kaffeebohnen mühsam mit einem ausgehölten Baumstumpf und einem Holzmörser\", schreiben Cold und Ferderbar.\\nDie grünen, ungerösteten Bohnen reisten mit zum Flughafen von San Salvador und weiter nach Altlanta. Von dort ging es nach London - \"ausnahmsweise mit einem kommerziellen Spediteur\", schreibt Kate. Auf der Webseite steht noch, dass sie in Bristol per Western Union 719 Pfund nach San Salvador für die Kaffeebäuerin Blanca geschickt hat. Von London wurde der Kaffee zur Rösterei \"Coffee Compass\" in Littlehampton transportiert. Anschließend ging es weiter ins 150 Kilometer entfernte Bristol.\\nKurz vor meiner Reise nach Schottland überweise ich Kate für beide Päckchen acht Pfund per Paypal. Ein Teil des Geldes geht an die Bauern, einen Teil behält Kate als Gewinn. Wie viel, ist aus ihrer Auflistung auf dem Päckchen zu sehen. Die Kuriere bekommen nichts. Manchmal erhielten sie als Dankeschön ein bisschen Kaffee, etwas Schokolade oder Olivenöl, sagt Kate. \"Die meisten machen das aus Interesse und Neugier.\" Was der Produzent bekommt, bestimmt dieser selbst.\\nDas ist anders als bei Fairtrade, denn dort setzt die Organisation - nach Gesprächen mit dutzenden Produzenten - Mindestpreise und Zuschläge für alle fest. Der Feraltrade-Handel funktioniert nach dem Prinzip: Du nennst mir den Preis und ich entscheide, ob ich deine Ware kaufen möchte - so wie auf lokalen Märkten üblich. \"Fairtrade-Produzenten müssen dagegen beständig lächeln, ihre Produkte fröhlich herzeigen und erklären, dass sie den Lohn für die Bildung der Kinder verwenden. Aber letztlich geht es mich als Käufer doch nichts an, wofür Produzenten ihr Geld verwenden\", sagt Kate. Dass die Produzenten im Gegenzug nichts dabei mitzureden haben, wofür die Konsumenten sonst so ihr Geld ausgeben oder woher sie ihr Einkommen beziehen, sei nicht gerade \"fair\". \"Die Beziehung ist einseitig und undurchsichtig.\" Denn auch der Produzent würde in den Vordergrund gerückt im Gegensatz zum Rest der Kette: Von Agenten, Versandarbeitern, Verschiffungspersonal oder Röstern erfahre man wenig.\\n\"Hi Christine, sorry, dass wir es nicht früher geschafft haben, uns bei dir zu melden. Wir haben das Feraltrade-Kaffe-Päckchen weiterhin in unserer Galerie\", schreibt Carly von der Collective-Gallery in Edinburgh. Ich bin seit einer Woche wieder in Berlin. Zwei Mal hatte ich vergeblich bei der Galerie angeklopft. Meine Mail blieb während meines Schottland-Aufenthalts unbeantwortet. Ich gebe Magnus Bescheid. \"Es duftet großartig\", mailt er mir ein paar Tage später aus Edingburgh.\\nArtikel erschienen am 02. November 2012 in: \"Wiener Zeitung\", Beilage \"Wiener Journal\", S. 10-13.\\n'}\n",
      "\n",
      "Sample article metadata:\n",
      " filename    1-coffee-to-berlin.json\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Number of selected articles: 2\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load filtered data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "filtered_data_path = os.path.join(\"..\", \"data\", \"filtered_data.json\")\n",
    "\n",
    "with open(filtered_data_path, \"r\") as file:\n",
    "    filtered_articles = json.load(file)\n",
    "\n",
    "print(f\"Number of articles: {len(filtered_articles)}\\n\")\n",
    "print(f\"Sample article metadata:\\n {filtered_metadata.iloc[0]}\\n\")\n",
    "print(f\"Sample article:\\n {filtered_articles[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple vector database"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:02:23.063999Z",
     "start_time": "2025-03-19T20:02:23.059976Z"
    }
   },
   "source": [
    "def get_documents_from_path(filenames: list[str]) -> [Document]:\n",
    "    documents = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        text = file.get(\"text\", \"\")\n",
    "        documents.append(Document(page_content=text, metadata={\n",
    "            \"title\": file.get(\"title\", \"\"),\n",
    "            \"author\": file.get(\"author\", \"\"),\n",
    "            \"published_at\": file.get(\"published_at\", \"\"),\n",
    "            \"id\": file.get(\"id\", \"\"),\n",
    "        }))\n",
    "\n",
    "    return documents"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:02:33.636335Z",
     "start_time": "2025-03-19T20:02:33.633838Z"
    }
   },
   "source": [
    "documents = get_documents_from_path(filtered_articles)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T20:02:38.374853Z",
     "start_time": "2025-03-19T20:02:34.976860Z"
    }
   },
   "source": [
    "# Create database\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, separators=[\"\\n\\n\", \"\\n\"])\n",
    "\n",
    "# Split documents and create vector database\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "# embeddings_client = OpenAIEmbeddings()\n",
    "\n",
    "# TODO get this working\n",
    "embeddings_client = get_openai_embeddings_client()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "db = FAISS.from_documents(texts, embeddings_client)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count build embedding token number\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "build_token_count = sum([len(tokenizer.encode(doc.page_content)) for doc in texts])\n",
    "print(f\"Token count: {build_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the database\n",
    "with open(DB_PATH, \"wb\") as f:\n",
    "    pickle.dump(db.serialize_to_bytes(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.5,  # <-- Gemini Free Tier\n",
    "    check_every_n_seconds=0.1,\n",
    ")\n",
    "\n",
    "llm = get_llm_client(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",  # TODO still necessary?\n",
    "    max_tokens=1024,\n",
    "    temperature=0.2,\n",
    "    rate_limiter=rate_limiter,\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert assistant. Use only the following retrieved context to answer the question accurately and concisely. \n",
    "If nothing is mentioned in the context, say \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], \n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    response = retrieval_chain.invoke({\"query\": query})\n",
    "    print(f\"Question: {query}\\nAnswer: {response['result']}\")\n",
    "    print(\"\\nSources: \\n\")\n",
    "    for source in response[\"source_documents\"]:\n",
    "        print(source.metadata)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_question(\"What was the Austrian GDP development in recent decades?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
